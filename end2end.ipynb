{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  \n",
    "title: End2End Spatial RecSys\n",
    "author: Juan Guillermo  \n",
    "description: End-to-end implementation of a recommendation system for retail store placement.  \n",
    "             The system analyzes historical store locations and integrates fine-grained  \n",
    "             demographic and socioeconomic data from U.S. ZIP codes. Using machine learning,  \n",
    "             it predicts optimal locations for new stores by predicting ZIP codes with a high  \n",
    "             probability of a new opening. The underlying probability model ranks  \n",
    "             potential store locations in U.S. states not included in the training data.  \n",
    "image_path: assets/site_recommendation_system_network_plot.html\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file created successfully.\n"
     ]
    }
   ],
   "source": [
    "excluded_states = \"Pennsylvania,Ohio,North Carolina\"\n",
    "showoff_states = \"Michigan,Florida\"\n",
    "\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write('APP_HOME=\"C:/Users/57320/Desktop/forecast_optimization_ux/thid_party_apps/location_recommendation_system\"\\n')\n",
    "    f.write(f'HOLD_OUT_STATES=\"{excluded_states}\"\\n')\n",
    "    f.write(f'SHOW_OFF_STATES=\"{showoff_states}\"\\n')\n",
    "\n",
    "print(\".env file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plot_styles.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile plot_styles.py \n",
    "\"\"\"\n",
    "title: plot styles\n",
    "description: Defines several decorators to distributes a custom styles across the plotly figures of a project,\n",
    "             thus providing standardization and a cohesive style. Full suport on plotly. Partial support on Folium\n",
    "             maps\n",
    "\"\"\"\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import functools\n",
    "import textwrap\n",
    "import functools\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "\n",
    "\n",
    "def transparent_background():\n",
    "    \"\"\"\n",
    "    Decorator to set a fully transparent background for a Plotly figure.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            fig = func(*args, **kwargs)\n",
    "            fig.update_layout(\n",
    "                paper_bgcolor='rgba(0,0,0,0)',  # Fully transparent background\n",
    "                plot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area\n",
    "            )\n",
    "            return fig\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def methodological_clarification(clarification_text, words_per_line=100):\n",
    "    \"\"\"\n",
    "    Decorator to add methodological clarification text to a Plotly figure.\n",
    "    - Wraps text every `words_per_line` words by inserting line breaks.\n",
    "    - Adjusts margins for better positioning.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            fig = func(*args, **kwargs)\n",
    "            wrapped_text = \"<br>\".join(textwrap.wrap(clarification_text, width=words_per_line))\n",
    "            fig.add_annotation(\n",
    "                text=wrapped_text,\n",
    "                showarrow=False,\n",
    "                xref=\"paper\", yref=\"paper\",\n",
    "                x=0.5, y=0,  # Moved 5% closer (was -0.02)\n",
    "                xanchor=\"center\", yanchor=\"top\",\n",
    "                font=dict(size=12, color=\"black\"),\n",
    "                align=\"center\"\n",
    "            )\n",
    "            fig.update_layout(margin=dict(l=15, r=15, t=55, b=50))  # Adjusted margins closer\n",
    "            return fig\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def centered_title(title_text, title_coords=\"tightly_integrated\"):\n",
    "    \"\"\"\n",
    "    Decorator to add a centered title slightly above the plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - title_text (str): The text of the title.\n",
    "    - title_coords (tuple or str): \n",
    "        - A tuple (x, y) to manually position the title.\n",
    "        - If \"tightly_integrated\", uses the default (0.5, 0.85).\n",
    "    \n",
    "    Defaults:\n",
    "    - If `title_coords=\"tightly_integrated\"`, places the title at (x=0.5, y=0.85).\n",
    "    - If a tuple (x, y) is provided, it is used directly.\n",
    "    \"\"\"\n",
    "    # Handle the default case\n",
    "    if title_coords == \"tightly_integrated\":\n",
    "        x, y = 0.5, 0.85\n",
    "    elif isinstance(title_coords, tuple) and len(title_coords) == 2:\n",
    "        x, y = title_coords\n",
    "    else:\n",
    "        raise ValueError(\"title_coords must be either 'tightly_integrated' or a tuple (x, y).\")\n",
    "\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            fig = func(*args, **kwargs)\n",
    "\n",
    "            # Add the centered annotation\n",
    "            fig.add_annotation(\n",
    "                text=title_text,\n",
    "                showarrow=False,\n",
    "                xref=\"paper\", yref=\"paper\",\n",
    "                x=x, y=y,\n",
    "                xanchor=\"center\", yanchor=\"bottom\",\n",
    "                font=dict(size=16, color=\"black\", family=\"Arial\"),\n",
    "                align=\"center\"\n",
    "            )\n",
    "\n",
    "            # Preserve existing margins while ensuring a reasonable top margin\n",
    "            existing_margins = fig.layout.margin.to_plotly_json() if hasattr(fig.layout, \"margin\") else {}\n",
    "            fig.update_layout(\n",
    "                margin={**existing_margins, \"t\": max(existing_margins.get(\"t\", 0), 50)}\n",
    "            )\n",
    "\n",
    "            return fig\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def apply_typography():\n",
    "    \"\"\"\n",
    "    Decorator to enforce a rigorous and minimalist font style in Plotly figures.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            fig = func(*args, **kwargs)\n",
    "            fig.update_layout(\n",
    "                font=dict(family=\"Lato, sans-serif\", size=14, color=\"black\"),\n",
    "                title=dict(font=dict(size=18, family=\"Lato, sans-serif\", color=\"black\", weight=\"bold\")),\n",
    "                xaxis=dict(title=dict(font=dict(size=14, family=\"Lato, sans-serif\", color=\"black\"))),\n",
    "                yaxis=dict(title=dict(font=dict(size=14, family=\"Lato, sans-serif\", color=\"black\"))),\n",
    "            )\n",
    "            return fig\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def save_plot_as_html(filepath=\"plot.html\"):\n",
    "    \"\"\"\n",
    "    Decorator to save a Plotly figure or Folium map as an HTML file.\n",
    "    \n",
    "    - Detects if the returned object is a Plotly `go.Figure` or a Folium `Map`.\n",
    "    - Saves appropriately and prints which case was matched.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            fig = func(*args, **kwargs)  # Call the decorated function\n",
    "            \n",
    "            if isinstance(fig, go.Figure):\n",
    "                print(f\"[INFO] Matched: Plotly Figure. Saving to {filepath}.\")\n",
    "                fig.write_html(filepath)\n",
    "\n",
    "            elif isinstance(fig, folium.Map):\n",
    "                print(f\"[INFO] Matched: Folium Map. Saving to {filepath}.\")\n",
    "                fig.save(filepath)\n",
    "\n",
    "            else:\n",
    "                print(\"[WARNING] No match found. Returning object as is.\")\n",
    "\n",
    "            return fig  # Return the original figure/map\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spatial_features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spatial_features.py\n",
    "\"\"\"\n",
    "title: Spatial Features\n",
    "description: Provides a dataframe with zip level spatial features from the US\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "APP_HOME = os.getenv(\"APP_HOME\")\n",
    "\n",
    "if not APP_HOME:\n",
    "    raise ValueError(\"APP_HOME environment variable not found. Please set it in the .env file.\")\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(APP_HOME)\n",
    "\n",
    "# Load the dataset\n",
    "zip_features = pd.read_csv('data/income_new.csv')\n",
    "\n",
    "# Standardizing ZIP code\n",
    "zip_features[\"zip_code\"] = zip_features[\"ZIP\"].astype(str)\n",
    "\n",
    "# Selecting relevant columns\n",
    "zip_features = zip_features[\n",
    "    [col for col in zip_features.columns if re.search(\"(zip_code)|(Hous)|(Fam)|(Marr)|(Non)\", col)]\n",
    "]\n",
    "\n",
    "# Display DataFrame information\n",
    "print(zip_features.info())\n",
    "\n",
    "# Dictionary for term replacements\n",
    "abbreviations = {\n",
    "    'Households': 'Hs',\n",
    "    'Less Than': 'LT',\n",
    "    'Nonfamily Households': 'NFHs',\n",
    "    'Married-Couple Families': 'MCF',\n",
    "    'Families': 'Fam',\n",
    "    'Median Income (Dollars)': 'MedInc',\n",
    "    'Mean Income (Dollars)': 'MeanInc',\n",
    "    'Income in the Past 12 Months': 'Inc12M',\n",
    "    ' to ': '-',\n",
    "    '$': '',\n",
    "}\n",
    "\n",
    "# Function to replace all terms and abbreviate numbers\n",
    "def abbreviate_names(name):\n",
    "    for long, short in abbreviations.items():\n",
    "        name = name.replace(long, short)\n",
    "    name = name.replace('100,000', '100k')\n",
    "    name = name.replace('150,000', '150k')\n",
    "    name = name.replace('200,000', '200k')\n",
    "    return name\n",
    "\n",
    "# Apply abbreviation function\n",
    "zip_features.columns = [abbreviate_names(col) for col in zip_features.columns]\n",
    "\n",
    "# Save the processed file\n",
    "#zip_features.to_csv(\"data/processed_income_features.csv\", index=False)\n",
    "#print(\"Processed file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stores_placements.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stores_placements.py\n",
    "\"\"\"\n",
    "title: Store Placements Processing\n",
    "description: This script processes store locations and standardizes ZIP codes.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from dotenv import load_dotenv\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "APP_HOME = os.getenv(\"APP_HOME\")\n",
    "\n",
    "if not APP_HOME:\n",
    "    raise ValueError(\"APP_HOME environment variable not found. Please set it in the .env file.\")\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(APP_HOME)\n",
    "\n",
    "# Load the dataset\n",
    "stores_df = pd.read_csv(\"data/trader_joes.csv\")\n",
    "\n",
    "# Standardizing ZIP code\n",
    "stores_df[\"zip_code\"] = stores_df[\"zip_code\"].astype(str)\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "stores_gdf = gpd.GeoDataFrame(stores_df, geometry=gpd.points_from_xy(stores_df.longitude, stores_df.latitude))\n",
    "\n",
    "# Display GeoDataFrame information\n",
    "print(stores_gdf.info())\n",
    "\n",
    "# Save the processed GeoDataFrame (optional)\n",
    "# stores_gdf.to_file(\"data/processed_trader_joes.geojson\", driver=\"GeoJSON\")\n",
    "# print(\"Processed GeoDataFrame saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spatial_frame.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spatial_frame.py\n",
    "\"\"\"\n",
    "title: Spatial Frame Processing\n",
    "description: This script processes spatial data from shapefiles and standardizes ZIP codes.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "APP_HOME = os.getenv(\"APP_HOME\")\n",
    "\n",
    "if not APP_HOME:\n",
    "    raise ValueError(\"APP_HOME environment variable not found. Please set it in the .env file.\")\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(APP_HOME)\n",
    "\n",
    "# Load the shapefile\n",
    "spatial_frame = gpd.read_file(\"zips_with_states.shp\")\n",
    "\n",
    "# Standardizing ZIP code\n",
    "spatial_frame[\"zip_code\"] = spatial_frame[\"zip_code\"].astype(str)\n",
    "\n",
    "# Display DataFrame information\n",
    "print(spatial_frame.info())\n",
    "\n",
    "# Save the processed file (optional)\n",
    "# spatial_frame.to_file(\"data/processed_zips_with_states.shp\")\n",
    "# print(\"Processed spatial data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_manager.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_manager.py\n",
    "\"\"\"\n",
    "title: Data Manager\n",
    "description: Handles ingestion merge and exploratory plottin of 3 data sources\n",
    "             for spatial analysis.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "class StoreLocationDataManager:\n",
    "    \n",
    "    #\n",
    "    # (0) initialization\n",
    "    #\n",
    "    def __init__(self, \n",
    "                 stores_df: pd.DataFrame, \n",
    "                 spatial_frame: gpd.GeoDataFrame, \n",
    "                 zip_features: pd.DataFrame, \n",
    "                 zip_id_col: str = \"zip_code\",\n",
    "                 state_column: str = \"NAME\"):\n",
    "        #\n",
    "        # inputs for spatial inference\n",
    "        #\n",
    "        self.stores_df = stores_df\n",
    "        self.spatial_frame = spatial_frame\n",
    "        self.zip_features = zip_features\n",
    "        self.zip_id_col = zip_id_col\n",
    "        self.state_column = state_column\n",
    "\n",
    "        # Validate the common key and state column\n",
    "        self._validate_zip_id_col()\n",
    "        self._validate_state_column()\n",
    "\n",
    "        # Precompute unique state names\n",
    "        self.unique_states = set(self.spatial_frame[self.state_column].dropna().unique())\n",
    "    #\n",
    "    def _validate_zip_id_col(self):\n",
    "        \"\"\"Ensure the common key exists and is a string in all dataframes.\"\"\"\n",
    "        datasets = {\n",
    "            \"stores_df\": self.stores_df,\n",
    "            \"spatial_frame\": self.spatial_frame,\n",
    "            \"zip_features\": self.zip_features\n",
    "        }\n",
    "        \n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            if self.zip_id_col not in dataset.columns:\n",
    "                raise ValueError(f\"Common key '{self.zip_id_col}' not found in {dataset_name}.\")\n",
    "            if not pd.api.types.is_string_dtype(dataset[self.zip_id_col]):\n",
    "                raise TypeError(f\"Common key '{self.zip_id_col}' in {dataset_name} must be of type str.\")\n",
    "            if dataset[self.zip_id_col].isna().any():\n",
    "                raise ValueError(f\"Common key '{self.zip_id_col}' contains NaN values in {dataset_name}.\")\n",
    "    #\n",
    "    def _validate_state_column(self):\n",
    "        \"\"\"Ensure the state column exists and contains valid data.\"\"\"\n",
    "        if self.state_column not in self.spatial_frame.columns:\n",
    "            raise ValueError(f\"State column '{self.state_column}' not found in spatial_frame.\")\n",
    "        if not pd.api.types.is_string_dtype(self.spatial_frame[self.state_column]):\n",
    "            raise TypeError(f\"State column '{self.state_column}' must be of type str.\")\n",
    "        if self.spatial_frame[self.state_column].isna().any():\n",
    "            raise ValueError(f\"State column '{self.state_column}' contains NaN values.\")\n",
    "\n",
    "    #\n",
    "    # (1) Plotting store locations on a map\n",
    "    #\n",
    "    def plot_store_location(self, \n",
    "                            state_name: str, \n",
    "                            zoom_start: int = 6, \n",
    "                            min_zoom: int = 6\n",
    "                            ):\n",
    "        \"\"\"Generate an interactive map showing store locations in the given state.\"\"\"\n",
    "        \n",
    "        # Validate state name\n",
    "        if state_name not in self.unique_states:\n",
    "            raise ValueError(f\"State '{state_name}' not found in the spatial data.\")\n",
    "\n",
    "        # Filter spatial data for the given state\n",
    "        state_frame = self.spatial_frame[self.spatial_frame[self.state_column] == state_name]\n",
    "\n",
    "        # Compute map center\n",
    "        centroid = state_frame.geometry.centroid\n",
    "        map_center = [centroid.y.mean(), centroid.x.mean()]\n",
    "        \n",
    "        # Create map\n",
    "        map_location = folium.Map(\n",
    "            location=map_center, \n",
    "            zoom_start=zoom_start,\n",
    "            min_zoom=min_zoom\n",
    "        )\n",
    "        \n",
    "        # Add state boundary\n",
    "        folium.GeoJson(\n",
    "            state_frame.to_json(),\n",
    "            name=state_name,\n",
    "            style_function=lambda feature: {\n",
    "                'fillColor': 'blue',\n",
    "                'color': 'white',\n",
    "                'weight': 0.5,\n",
    "                'fillOpacity': 0.4\n",
    "            }\n",
    "        ).add_to(map_location)\n",
    "\n",
    "        \n",
    "        # Find matching stores in the state\n",
    "        matched_stores = self.stores_df[self.stores_df[self.zip_id_col].isin(state_frame[self.zip_id_col])]\n",
    "        for _, row in matched_stores.iterrows():\n",
    "            store_name = row.get('store_name', \"Unnamed Store\")\n",
    "            folium.Marker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                popup=store_name\n",
    "            ).add_to(map_location)\n",
    "        \n",
    "        return map_location\n",
    "    \n",
    "    #\n",
    "    def _left_join(self, left_table: str, right_table: str) -> pd.DataFrame:\n",
    "        \"\"\"Perform a left join between two of the class's main tables using zip_id_col.\"\"\"\n",
    "        \n",
    "        # Validate table names\n",
    "        valid_tables = {\n",
    "            \"stores_df\": self.stores_df,\n",
    "            \"spatial_frame\": self.spatial_frame,\n",
    "            \"zip_features\": self.zip_features\n",
    "        }\n",
    "        \n",
    "        if left_table not in valid_tables:\n",
    "            raise ValueError(f\"Invalid left table '{left_table}'. Must be one of {list(valid_tables.keys())}.\")\n",
    "        if right_table not in valid_tables:\n",
    "            raise ValueError(f\"Invalid right table '{right_table}'. Must be one of {list(valid_tables.keys())}.\")\n",
    "        \n",
    "        left_df = valid_tables[left_table]\n",
    "        right_df = valid_tables[right_table]\n",
    "\n",
    "        # Validate presence of zip_id_col\n",
    "        if self.zip_id_col not in left_df.columns:\n",
    "            raise ValueError(f\"Key '{self.zip_id_col}' not found in {left_table}.\")\n",
    "        if self.zip_id_col not in right_df.columns:\n",
    "            raise ValueError(f\"Key '{self.zip_id_col}' not found in {right_table}.\")\n",
    "        \n",
    "        return left_df.merge(right_df, on=self.zip_id_col, how='left')\n",
    "\n",
    "    #\n",
    "    def plot_stores_summary_per_state(self, household_col: str = \"Hs\", drop_highest_pct: float = 5.0):\n",
    "        \"\"\"Plots the number of stores vs household count per state, with a quadratic regression fit.\n",
    "        Drops the top X% of states by household count before fitting.\n",
    "\n",
    "        Args:\n",
    "            household_col (str): Column name in zip_features containing household counts. Defaults to \"Hs\".\n",
    "            drop_highest_pct (float): Percentage of states with the highest household counts to drop before regression. Defaults to 5%.\n",
    "        \"\"\"\n",
    "\n",
    "        # (1) Get store count per state\n",
    "        stores_per_state = self._left_join(\"stores_df\", \"spatial_frame\")\n",
    "        stores_count = stores_per_state[self.state_column].value_counts().reset_index()\n",
    "        stores_count.columns = [\"State\", \"Store Count\"]\n",
    "\n",
    "        # (2) Merge zip_features with spatial_frame to get households per zip\n",
    "        zip_with_states = self._left_join(\"zip_features\", \"spatial_frame\")\n",
    "\n",
    "        # (3) Summarize household count per state\n",
    "        if household_col not in zip_with_states.columns:\n",
    "            raise ValueError(f\"Column '{household_col}' is missing in zip_features.\")\n",
    "        households_per_state = zip_with_states.groupby(self.state_column)[household_col].sum().reset_index()\n",
    "        households_per_state.columns = [\"State\", \"Total Households\"]\n",
    "\n",
    "        # (4) Merge store count with household count\n",
    "        merged_df = stores_count.merge(households_per_state, on=\"State\", how=\"left\")\n",
    "\n",
    "        # (5) Remove top X% of states based on household count\n",
    "        num_states_to_drop = int(len(merged_df) * (drop_highest_pct / 100))\n",
    "        dropped_states = merged_df.nlargest(num_states_to_drop, \"Total Households\")[\"State\"].tolist()\n",
    "        filtered_df = merged_df[~merged_df[\"State\"].isin(dropped_states)]\n",
    "\n",
    "        # (6) Compute store density (Stores per 10,000 households)\n",
    "        filtered_df[\"Stores per 10k Households\"] = (filtered_df[\"Store Count\"] / filtered_df[\"Total Households\"]) * 10000\n",
    "\n",
    "        # (7) Fit Quadratic Regression (2nd-degree polynomial)\n",
    "        X = filtered_df[\"Total Households\"]\n",
    "        y = filtered_df[\"Store Count\"]\n",
    "        coeffs = np.polyfit(X, y, 2)  # Quadratic fit: y = ax² + bx + c\n",
    "        poly_eq = np.poly1d(coeffs)\n",
    "        X_fit = np.linspace(X.min(), X.max(), 100)\n",
    "        y_fit = poly_eq(X_fit)\n",
    "\n",
    "        # (8) Create Scatterplot\n",
    "        fig = px.scatter(\n",
    "            filtered_df,\n",
    "            x=\"Total Households\",\n",
    "            y=\"Store Count\",\n",
    "            text=\"State\",\n",
    "            size=\"Stores per 10k Households\",\n",
    "            title=\"Number of Stores vs Household Count per State\",\n",
    "            labels={\"Total Households\": \"Total Households\", \"Store Count\": \"Number of Stores\"},\n",
    "        )\n",
    "\n",
    "        # (9) Add Regression Fit Line\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=X_fit,\n",
    "            y=y_fit,\n",
    "            mode=\"lines\",\n",
    "            line=dict(dash=\"dot\", color=\"red\", width=2),\n",
    "            name=\"Quadratic Fit\"\n",
    "        ))\n",
    "\n",
    "        # (10) Caption with dropped states\n",
    "        dropped_caption = f\"Dropped top {drop_highest_pct}% states (by household count): {', '.join(dropped_states)}\"\n",
    "        fig.add_annotation(\n",
    "            text=dropped_caption,\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            x=0.05, y=-0.15,\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"gray\"),\n",
    "        )\n",
    "\n",
    "        # (11) Style Updates\n",
    "        fig.update_traces(marker=dict(color=\"blue\", line=dict(width=2, color=\"white\")), textposition=\"top center\")\n",
    "        fig.update_layout(title_x=0.5, xaxis=dict(showgrid=True), yaxis=dict(showgrid=True))\n",
    "\n",
    "        #fig.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting perform_exploratory_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_exploratory_analysis.py\n",
    "\"\"\"\n",
    "title: Perform Exploratory Analysis\n",
    "description: Merges the data sources for spatial analysis and produces exploratory plots\n",
    "image_path: {stores_summary.html,plot_store_location_*}\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from spatial_features import zip_features\n",
    "from stores_placements import stores_gdf\n",
    "from spatial_frame import spatial_frame\n",
    "from data_manager import StoreLocationDataManager\n",
    "from plotly_styles import (\n",
    "    save_plot_as_html, centered_title, methodological_clarification,\n",
    "    transparent_background\n",
    "    )\n",
    "\n",
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "SHOW_OFF_STATES = [state.strip() for state in os.getenv(\"SHOW_OFF_STATES\").split(',')]\n",
    "SHOW_OFF_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_exploratory_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_exploratory_analysis.py -a\n",
    "\n",
    "# Instantiate the data manager\n",
    "data_manager = StoreLocationDataManager(\n",
    "    stores_df=stores_gdf,\n",
    "    spatial_frame=spatial_frame,\n",
    "    zip_features=zip_features,\n",
    "    zip_id_col=\"zip_code\",  # Adjust if a different column name is used\n",
    "    state_column=\"NAME\"  # Adjust if a different column name is used for states\n",
    ")\n",
    "\n",
    "# Confirm successful instantiation\n",
    "print(\"StoreLocationDataManager successfully instantiated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_exploratory_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_exploratory_analysis.py -a\n",
    "\n",
    "# Apply decorators one by one, with their specific parameters\n",
    "data_manager.plot_stores_summary_per_state = transparent_background()(\n",
    "    data_manager.plot_stores_summary_per_state\n",
    ")\n",
    "\n",
    "data_manager.plot_stores_summary_per_state = methodological_clarification(\n",
    "    clarification_text=\"This analysis is based on 2024 store data.\", \n",
    "    #words_per_line=80\n",
    ")(\n",
    "    data_manager.plot_stores_summary_per_state\n",
    ")\n",
    "\n",
    "data_manager.plot_stores_summary_per_state = centered_title(\n",
    "    title_text=\"Store Summary per State\", \n",
    "    title_coords=(0.5, 0.9)  # Adjust position if needed\n",
    ")(\n",
    "    data_manager.plot_stores_summary_per_state\n",
    ")\n",
    "\n",
    "data_manager.plot_stores_summary_per_state = save_plot_as_html(\n",
    "    filepath=\"stores_summary.html\"\n",
    ")(\n",
    "    data_manager.plot_stores_summary_per_state\n",
    ")\n",
    "\n",
    "# Step 5: Call the decorated method\n",
    "data_manager.plot_stores_summary_per_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_exploratory_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_exploratory_analysis.py -a\n",
    "\n",
    "for state in SHOW_OFF_STATES:\n",
    "    filepath = f\"plot_store_location_{state}.html\"\n",
    "    \n",
    "    # Dynamically wrap the function for each state\n",
    "    decorated_function = save_plot_as_html(filepath=filepath)(\n",
    "        data_manager.plot_store_location\n",
    "    )\n",
    "    \n",
    "    # Call the function to generate and save the map\n",
    "    print(f\"Generating and saving plot for {state}...\")\n",
    "    decorated_function(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spatial_correlation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spatial_correlation.py\n",
    "\"\"\"\n",
    "title: Spatial Correlation\n",
    "description: Elaborates StoreLocationDataManager. It provides methods to asses the correlation pattern\n",
    "             between zip level features and the stores location.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "import plotly.express as px\n",
    "from shapely.geometry import Point\n",
    "from folium.plugins import Draw, MeasureControl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_manager import StoreLocationDataManager\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "HOLD_OUT_STATES = [state.strip() for state in os.getenv(\"HOLD_OUT_STATES\").split(',')]\n",
    "HOLD_OUT_STATES\n",
    "\n",
    "print(f\"[INFO] Hold-out states: {HOLD_OUT_STATES}\")\n",
    "\n",
    "class SpatialCorrelation(StoreLocationDataManager):\n",
    "    def __init__(self, spatial_resolution=0.2, hold_out_states=HOLD_OUT_STATES, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # Pass additional parameters to the parent class\n",
    "        self.spatial_resolution = spatial_resolution\n",
    "        self.hold_out_states = hold_out_states\n",
    "        self.determine_target_classification()  # Ensure raw_target is set at instantiation\n",
    "    \n",
    "    def determine_target_classification(self):\n",
    "        \"\"\"Classify locations as part of store proximity or holdout exclusions.\"\"\"\n",
    "        print(f\"[INFO] Excluding states: {self.hold_out_states}\")\n",
    "        self.spatial_frame['raw_target'] = 0  # Initialize everything as neutral\n",
    "        \n",
    "        # Flag states to be excluded\n",
    "        self.spatial_frame.loc[self.spatial_frame[self.state_column].isin(self.hold_out_states), 'raw_target'] = -1\n",
    "\n",
    "        # Compute store buffers\n",
    "        store_buffers = self.stores_df.geometry.buffer(self.spatial_resolution)\n",
    "\n",
    "        # Find positive examples (store proximity), ensuring excluded states remain -1\n",
    "        positives_geo = gpd.sjoin(\n",
    "            self.spatial_frame[self.spatial_frame['raw_target'] == 0],  # Ignore excluded states\n",
    "            gpd.GeoDataFrame(geometry=store_buffers), \n",
    "            how='inner', op='intersects'\n",
    "        )\n",
    "\n",
    "        self.spatial_frame.loc[positives_geo.index, 'raw_target'] = 1\n",
    "    \n",
    "    def get_samples(self, neg_to_pos_ratio=5, **kwargs):\n",
    "        \"\"\"Retrieve training and testing samples while respecting hold-out exclusions.\"\"\"\n",
    "        print(f\"[INFO] Generating samples while excluding states: {self.hold_out_states}\")\n",
    "        neg_to_pos_ratio = int(neg_to_pos_ratio)\n",
    "\n",
    "        self.spatial_frame['target'] = self.spatial_frame['raw_target']\n",
    "        positives = self.spatial_frame[self.spatial_frame['target'] == 1]\n",
    "        potential_negatives = self.spatial_frame[self.spatial_frame['target'] == 0]  # Use 0 instead of -1\n",
    "        \n",
    "        if len(positives) * neg_to_pos_ratio > len(potential_negatives):\n",
    "            warnings.warn('Not enough negatives to match the ratio without replacement. Enabling replacement.')\n",
    "            sampled_negatives = potential_negatives.sample(n=len(positives) * neg_to_pos_ratio, replace=True, random_state=42)\n",
    "        else:\n",
    "            sampled_negatives = potential_negatives.sample(n=len(positives) * neg_to_pos_ratio, replace=False, random_state=42)\n",
    "\n",
    "        self.spatial_frame.loc[sampled_negatives.index, 'target'] = 0\n",
    "        filtered_data = self.spatial_frame[self.spatial_frame['target'].isin([1, 0])]\n",
    "        merged_data = filtered_data.merge(self.zip_features, how='left', on=self.zip_id_col)\n",
    "        merged_data = merged_data.dropna()\n",
    "\n",
    "        feature_columns = self.zip_features.columns.tolist()\n",
    "        X = merged_data[feature_columns]\n",
    "        y = merged_data['target']\n",
    "\n",
    "        valid_split_params = {'test_size', 'train_size', 'random_state', 'shuffle', 'stratify'}\n",
    "        split_params = {k: v for k, v in kwargs.items() if k in valid_split_params}\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.5, random_state=42, **split_params\n",
    "        )\n",
    "\n",
    "        return self.X_train, self.y_train, self.X_test, self.y_test\n",
    "    \n",
    "    def plot_correlation_bars(self, k=20):\n",
    "        X_train, y_train, _, _ = self.get_samples()\n",
    "        data = pd.concat([X_train, y_train.rename('store_proximity')], axis=1)\n",
    "        correlation_series = data.corr()['store_proximity'].drop('store_proximity')\n",
    "        \n",
    "        corr_df = correlation_series.abs().nlargest(k).reset_index()\n",
    "        corr_df.columns = ['Feature', 'Correlation']\n",
    "        \n",
    "        fig = px.bar(\n",
    "            corr_df, x='Feature', y='Correlation', text='Feature', color='Correlation',\n",
    "            color_continuous_scale=px.colors.diverging.Tropic, title=\"Feature Correlation with Store Proximity\"\n",
    "        )\n",
    "        \n",
    "        fig.update_traces(\n",
    "            marker=dict(line=dict(color='black', width=0.5), opacity=0.8),\n",
    "            texttemplate='%{text}', textposition='inside',\n",
    "            textfont=dict(color='white', size=12), insidetextanchor=\"start\"\n",
    "        )\n",
    "        return fig\n",
    "    \n",
    "    def plot_store_location_with_proximity(self, state_name):\n",
    "        if state_name not in self.spatial_frame[self.state_column].unique():\n",
    "            raise ValueError(f\"State '{state_name}' not found in the spatial data.\")\n",
    "        \n",
    "        state_frame = self.spatial_frame[self.spatial_frame[self.state_column] == state_name]\n",
    "        map_location = folium.Map(\n",
    "            location=[state_frame.geometry.centroid.y.mean(), state_frame.geometry.centroid.x.mean()],\n",
    "            zoom_start=6, min_zoom=6\n",
    "        )\n",
    "        \n",
    "        Draw(export=True).add_to(map_location)\n",
    "        MeasureControl().add_to(map_location)\n",
    "        \n",
    "        for target, color in zip([1, 0, -1], ['green', 'red', 'gray']):\n",
    "            folium.GeoJson(\n",
    "                state_frame[state_frame['target'] == target].to_json(),\n",
    "                name=f\"{'Positive' if target == 1 else 'Negative' if target == 0 else 'Neutral'} Examples\",\n",
    "                style_function=lambda x, color=color: {'fillColor': color, 'color': color, 'weight': 1, 'fillOpacity': 0.5}\n",
    "            ).add_to(map_location)\n",
    "        \n",
    "        state_stores = self.stores_df[self.stores_df[self.zip_id_col].isin(state_frame[self.zip_id_col])]\n",
    "        for _, row in state_stores.iterrows():\n",
    "            folium.CircleMarker(\n",
    "                location=[row['latitude'], row['longitude']], radius=2.5, color='black', fill=True,\n",
    "                fill_color='black', fill_opacity=0.5, popup=row.get('store_name', 'Store')\n",
    "            ).add_to(map_location)\n",
    "        \n",
    "        return map_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting perform_spatial_correlation_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_correlation_analysis.py\n",
    "\"\"\"\n",
    "title: Perform Spatial Correlation Analysis\n",
    "description: Performs the Spatial Correlation Analysis\n",
    "image_path: {correlation_bars.html,plot_store_location_with_proximity_*}\n",
    "\"\"\"\n",
    "\n",
    "from spatial_features import zip_features\n",
    "from stores_placements import stores_gdf\n",
    "from spatial_frame import spatial_frame\n",
    "from spatial_correlation import  SpatialCorrelation\n",
    "\n",
    "from plotly_styles import (\n",
    "    save_plot_as_html, centered_title, methodological_clarification,\n",
    "    transparent_background\n",
    "    )\n",
    "\n",
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "SHOW_OFF_STATES = [state.strip() for state in os.getenv(\"SHOW_OFF_STATES\").split(',')]\n",
    "SHOW_OFF_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_spatial_correlation_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_correlation_analysis.py -a\n",
    "# Inspect datasets\n",
    "#zip_features.info()\n",
    "#stores_df.info()\n",
    "#spatial_frame.info()\n",
    "\n",
    "# Instantiate the data manager\n",
    "sc =  SpatialCorrelation(\n",
    "    stores_df=stores_gdf,\n",
    "    spatial_frame=spatial_frame,\n",
    "    zip_features=zip_features,\n",
    "    zip_id_col=\"zip_code\",  # Adjust if a different column name is used\n",
    "    state_column=\"NAME\"  # Adjust if a different column name is used for states\n",
    ")\n",
    "\n",
    "# Confirm successful instantiation\n",
    "print(\"SpatialCorrelation successfully instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_spatial_correlation_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_correlation_analysis.py -a\n",
    "\n",
    "# Apply decorators one by one, with their specific parameters\n",
    "plot_correlation_bars = transparent_background()(\n",
    "    sc.plot_correlation_bars\n",
    ")\n",
    "\n",
    "plot_correlation_bars = methodological_clarification(\n",
    "    clarification_text=\"This analysis is based on 2024 store data.\", \n",
    "    #words_per_line=80\n",
    ")(\n",
    "    plot_correlation_bars\n",
    ")\n",
    "\n",
    "plot_correlation_bars = centered_title(\n",
    "    title_text=\"Store Summary per State\", \n",
    "    title_coords=(0.5, 0.9)  # Adjust position if needed\n",
    ")(\n",
    "    plot_correlation_bars\n",
    ")\n",
    "\n",
    "plot_correlation_bars = save_plot_as_html(\n",
    "    filepath=\"correlation_bars.html\"\n",
    ")(\n",
    "    plot_correlation_bars\n",
    ")\n",
    "\n",
    "# Step 5: Call the decorated method\n",
    "plot_correlation_bars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_spatial_correlation_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_correlation_analysis.py -a\n",
    "\n",
    "for state in SHOW_OFF_STATES:\n",
    "    filepath = f\"plot_store_location_with_proximity_{state}.html\"\n",
    "    \n",
    "    # Wrap the function dynamically for each state\n",
    "    decorated_function = save_plot_as_html(filepath=filepath)(\n",
    "        sc.plot_store_location_with_proximity\n",
    "    )\n",
    "    \n",
    "    # Call the function to generate and save the map\n",
    "    print(f\"Generating and saving proximity map for {state}...\")\n",
    "    decorated_function(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spatial_baseline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spatial_baseline.py\n",
    "\"\"\"\n",
    "title: Spatial Baseline\n",
    "description: Elaborates SpatialBaseline. It provides a baseline ML model to predict store placements\n",
    "             from underlyng data about the zip codes.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from shapely.geometry import Point\n",
    "from folium.plugins import Draw, MeasureControl\n",
    "from branca.colormap import linear\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spatial_correlation import SpatialCorrelation\n",
    "\n",
    "class SpatialBaseline(SpatialCorrelation):\n",
    "    \n",
    "    #\n",
    "    # (0) Initialization\n",
    "    #\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # Pass additional parameters to the parent class\n",
    "        \n",
    "        self.baseline_probabilities=None\n",
    "        self.fitted_model=None\n",
    "        self.fit_baseline()\n",
    "        \n",
    "    #\n",
    "    # (1) Fit model baseline\n",
    "    #\n",
    "    def fit_baseline(self, neg_to_pos_ratio=5):\n",
    "        \n",
    "        # Retrieve the data from get_samples\n",
    "        X_train, y_train, X_test, y_test = self.get_samples(neg_to_pos_ratio)\n",
    "\n",
    "        # Train the model\n",
    "        self.fitted_model = LogisticRegression()\n",
    "        self.fitted_model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        predictions = self.fitted_model.predict(X_test)\n",
    "        self.baseline_probabilities = self.fitted_model.predict_proba(X_test)[:, 1]\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1_score_value = f1_score(y_test, predictions)\n",
    "\n",
    "        # Optionally print or return the metrics\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"F1 Score:\", f1_score_value)\n",
    "        \n",
    "    #\n",
    "    # (2) plot probabilities\n",
    "    #   \n",
    "    \n",
    "    def _compute_probabilities(self, state_frame):\n",
    "        \"\"\"\n",
    "        Computes probabilities using the fitted model and merges them into the state frame.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.fitted_model is None:\n",
    "            raise ValueError(\"The model has not been fitted yet. Fit the model before plotting probabilities.\")\n",
    "\n",
    "        # Merge spatial data with features\n",
    "        merged_data = state_frame.merge(self.zip_features, how='left', on=self.zip_id_col)\n",
    "\n",
    "        # Ensure all necessary feature columns exist\n",
    "        feature_columns = self.zip_features.columns.tolist()\n",
    "        valid_data = merged_data.dropna(subset=feature_columns)\n",
    "\n",
    "        # Convert to numerical format\n",
    "        X = valid_data[feature_columns].values.astype(np.float32)\n",
    "\n",
    "        # Predict probabilities\n",
    "        valid_data[\"probabilities\"] = self.fitted_model.predict_proba(X)[:, 1]\n",
    "\n",
    "        # Ensure alignment of IDs\n",
    "        valid_data[self.zip_id_col] = merged_data[self.zip_id_col][valid_data.index]\n",
    "\n",
    "        # Merge back into the original state frame\n",
    "        probs = valid_data[[self.zip_id_col, \"probabilities\"]]\n",
    "        merged_data = merged_data.merge(probs, on=self.zip_id_col, how=\"left\")\n",
    "\n",
    "        return merged_data\n",
    "    #\n",
    "    def plot_probabilities(self, state_name, probabilities=None):\n",
    "        \"\"\"\n",
    "        Plot predicted probabilities for a given state using a choropleth map and store locations.\n",
    "        \n",
    "        If probabilities are provided, they are appended directly to the state frame.\n",
    "        Otherwise, the probabilities are computed using the fitted model, with missing values imputed using the median.\n",
    "        \"\"\"\n",
    "\n",
    "        # Ensure the state exists in spatial data\n",
    "        if state_name not in self.unique_states:\n",
    "            raise ValueError(f\"State '{state_name}' not found in the spatial data.\")\n",
    "\n",
    "        # Extract state-specific spatial frame\n",
    "        state_frame = self.spatial_frame[self.spatial_frame[self.state_column] == state_name].copy()\n",
    "\n",
    "        if probabilities is not None:\n",
    "            # Validate shape before appending probabilities\n",
    "            if len(probabilities) != len(state_frame):\n",
    "                raise ValueError(\"Provided probabilities do not match the number of state entries.\")\n",
    "            state_frame[\"probabilities\"] = probabilities\n",
    "\n",
    "        else:\n",
    "            # Compute probabilities using the fitted model\n",
    "            state_frame = self._compute_probabilities(state_frame)\n",
    "\n",
    "            # Impute missing probabilities with the median\n",
    "            if state_frame[\"probabilities\"].isnull().any():\n",
    "                median_prob = state_frame[\"probabilities\"].median()\n",
    "                state_frame[\"probabilities\"].fillna(median_prob, inplace=True)\n",
    "\n",
    "        #\n",
    "        # (1.1) base map\n",
    "        #\n",
    "\n",
    "        # Compute map center based on state's geographic centroid\n",
    "        centroid_y = state_frame.geometry.centroid.y.mean()\n",
    "        centroid_x = state_frame.geometry.centroid.x.mean()\n",
    "\n",
    "        # Create Folium map centered on the state\n",
    "        map_location = folium.Map(\n",
    "            location=[centroid_y, centroid_x],\n",
    "            zoom_start=6,\n",
    "            min_zoom=6  # Restrict zooming out\n",
    "        )\n",
    "\n",
    "        # Plot probabilities as a choropleth layer\n",
    "        folium.Choropleth(\n",
    "            geo_data=state_frame.to_json(),\n",
    "            data=state_frame,  # Since probabilities are now directly in state_frame\n",
    "            columns=[self.zip_id_col, \"probabilities\"],\n",
    "            key_on=f\"feature.properties.{self.zip_id_col}\",\n",
    "            fill_color=\"YlOrRd\",\n",
    "            fill_opacity=0.7,\n",
    "            line_opacity=0.2,\n",
    "            legend_name=\"Probability of Store Presence\"\n",
    "        ).add_to(map_location)\n",
    "\n",
    "        #\n",
    "        # (1.2) Layer in the store locations\n",
    "        #\n",
    "        colormap = linear.YlOrRd_09.scale(0, 1)\n",
    "\n",
    "        # Match stores based on ZIP code\n",
    "        matched_stores = self.stores_df[self.stores_df[self.zip_id_col].isin(state_frame[self.zip_id_col])]\n",
    "\n",
    "        for _, row in matched_stores.iterrows():\n",
    "            # Fetch probability for the store's ZIP code\n",
    "            prob = state_frame.loc[state_frame[self.zip_id_col] == row[self.zip_id_col], \"probabilities\"]\n",
    "\n",
    "            if not prob.empty:\n",
    "                probability = prob.values[0]  # Extract the probability value\n",
    "            else:\n",
    "                probability = 0  # Default to 0 if no probability is found\n",
    "\n",
    "            store_name = row.get(\"store_name\", f\"Store {_}\")\n",
    "\n",
    "            # Add store marker with probability-based coloring\n",
    "            folium.CircleMarker(\n",
    "                location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "                radius=8,\n",
    "                popup=f\"{store_name} - {probability:.2f}\",\n",
    "                color=\"black\",  # Border color\n",
    "                fill=True,\n",
    "                fill_color=colormap(probability),  # Fill color based on probability\n",
    "                fill_opacity=1  # Solid color fill\n",
    "            ).add_to(map_location)\n",
    "\n",
    "        # Add colormap legend\n",
    "        colormap.add_to(map_location)\n",
    "\n",
    "        return map_location  # Return the Folium map for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting perform_spatial_baseline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_baseline.py\n",
    "\"\"\"\n",
    "title: Perform Spatial Baseline\n",
    "description: Performs the training of baseline model to predict store placements from underlyng\n",
    "             zip data\n",
    "image_path: plot_probabilities_*\n",
    "\"\"\"\n",
    "\n",
    "from spatial_features import zip_features\n",
    "from stores_placements import stores_gdf\n",
    "from spatial_frame import spatial_frame\n",
    "from spatial_baseline import SpatialBaseline\n",
    "from plotly_styles import (\n",
    "    save_plot_as_html\n",
    "    )\n",
    "\n",
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "HOLD_OUT_STATES = [state.strip() for state in os.getenv(\"HOLD_OUT_STATES\").split(',')]\n",
    "HOLD_OUT_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_spatial_baseline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_baseline.py -a\n",
    "# Inspect datasets\n",
    "#zip_features.info()\n",
    "#stores_df.info()\n",
    "#spatial_frame.info()\n",
    "\n",
    "# Instantiate the spatial baseline\n",
    "sb =  SpatialBaseline(\n",
    "    stores_df=stores_gdf,\n",
    "    spatial_frame=spatial_frame,\n",
    "    zip_features=zip_features,\n",
    "    zip_id_col=\"zip_code\",  # Adjust if a different column name is used\n",
    "    state_column=\"NAME\",  # Adjust if a different column name is used for states\n",
    "    spatial_resolution=0.4\n",
    ")\n",
    "\n",
    "# Confirm successful instantiation\n",
    "print(\"SpatialBaseline successfully instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to perform_spatial_baseline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile perform_spatial_baseline.py -a\n",
    "\n",
    "# Inspect datasets\n",
    "for state in HOLD_OUT_STATES:\n",
    "    filepath = f\"plot_probabilities_{state}.html\"\n",
    "    \n",
    "    # Wrap the function dynamically for each state\n",
    "    decorated_function = save_plot_as_html(filepath=filepath)(\n",
    "        sb.plot_probabilities\n",
    "    )\n",
    "    \n",
    "    # Call the function to generate and save the plot\n",
    "    print(f\"Generating and saving probability plot for {state}...\")\n",
    "    decorated_function(state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
